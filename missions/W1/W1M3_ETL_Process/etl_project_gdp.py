import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import json
from tabulate import tabulate
from datetime import datetime
import os

# ìƒìˆ˜ ì„¤ì • (URL, íŒŒì¼ ê²½ë¡œ ë“±)
TARGET_URL = 'https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)'
REGION_MAPPING_FILE = 'data/country_region_table.json'
RAW_DATA_FILE = 'results/Countries_by_GDP.json'
PROCESSED_DATA_FILE = 'results/Countries_by_GDP_Processed.json'
LOG_FILE = 'log/etl_project_log.txt'

# ë¡œê·¸ ê¸°ë¡ í•¨ìˆ˜
def log_message(message):
    """
    etl_project_log.txt íŒŒì¼ì— ë¡œê·¸ ë©”ì‹œì§€ë¥¼ ê¸°ë¡í•˜ëŠ” í•¨ìˆ˜.
    ì‹¤í–‰ ì‹œê°„ì„ í¬í•¨í•˜ì—¬ "time, log" í˜•ì‹ìœ¼ë¡œ ê¸°ë¡.
    """
    with open(LOG_FILE, 'a') as f:
        current_time = datetime.now().strftime('%Y-%B-%d-%H-%M-%S')
        f.write(f"{current_time}, {message}\n")

# ì‹¤í–‰ êµ¬ë¶„ì„  ì¶”ê°€ í•¨ìˆ˜
def log_separator():
    """
    ë¡œê·¸ íŒŒì¼ì— ì‹¤í–‰ êµ¬ë¶„ì„ ì„ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜.
    ìƒˆë¡œìš´ ì‹¤í–‰ì´ ì‹œì‘ë  ë•Œë§ˆë‹¤ ì‹¤í–‰ ì‹œê°„ì„ ëª…í™•í•˜ê²Œ êµ¬ë¶„í•´ì¤Œ.
    """
    with open(LOG_FILE, 'a') as f:
        f.write("\n" + "="*50 + "\n")
        current_time = datetime.now().strftime('%Y-%B-%d-%H-%M-%S')
        f.write(f"ğŸš€ New Execution at {current_time}\n")
        f.write("="*50 + "\n\n")

# ë¡œê·¸ ë°ì½”ë ˆì´í„° (í•¨ìˆ˜ ì‹œì‘/ì¢…ë£Œ ì‹œ ìë™ìœ¼ë¡œ ë¡œê·¸ ê¸°ë¡)
def log_decorator(func):
    """
    í•¨ìˆ˜ì˜ ì‹¤í–‰ ì‹œì‘ê³¼ ì™„ë£Œë¥¼ ìë™ìœ¼ë¡œ ë¡œê·¸ì— ê¸°ë¡í•˜ëŠ” ë°ì½”ë ˆì´í„°.
    ê° í•¨ìˆ˜ê°€ ì‹œì‘ë  ë•Œ 'ì‹œì‘', ì™„ë£Œë  ë•Œ 'ì™„ë£Œ'ë¡œ í‘œì‹œí•˜ë©°, ê²°ê³¼ê°€ ìˆ«ìì¸ ê²½ìš° ê²°ê³¼ ê°’ë„ ê¸°ë¡.
    """
    def wrapper(*args, **kwargs):
        log_message(f"{func.__name__} ì‹œì‘")
        result = func(*args, **kwargs)
        log_message(f"{func.__name__} ì™„ë£Œ: {result if isinstance(result, int) else 'Success'}")
        return result
    return wrapper

# GDP ETL (ì¶”ì¶œ, ë³€í™˜, ì ì¬) í´ë˜ìŠ¤
class GDP_ETL:
    """
    GDP ë°ì´í„°ë¥¼ ì¶”ì¶œ, ë³€í™˜, ì ì¬í•˜ëŠ” ETL íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤.
    ETL í”„ë¡œì„¸ìŠ¤ì˜ ê° ë‹¨ê³„ë¥¼ í•¨ìˆ˜ë¡œ ë‚˜ëˆ„ì–´ ê´€ë¦¬í•˜ë©°, ì›¹ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ê°€ê³µ í›„ ì €ì¥.
    """

    def __init__(self, url):
        self.url = url
        self.soup = self._fetch_data()  # ì›¹ í˜ì´ì§€ì—ì„œ HTML ë°ì´í„° íŒŒì‹±

    def _fetch_data(self):
        """
        ì›¹ í˜ì´ì§€ì—ì„œ HTMLì„ ìš”ì²­í•˜ì—¬ BeautifulSoup ê°ì²´ë¡œ ë°˜í™˜.
        ìš”ì²­ ìƒíƒœì— ë”°ë¼ ì„±ê³µ ë˜ëŠ” ì‹¤íŒ¨ ë©”ì‹œì§€ë¥¼ ë¡œê·¸ì— ê¸°ë¡.
        """
        response = requests.get(self.url)
        if response.status_code == 200:
            log_message("ì›¹ í˜ì´ì§€ ìš”ì²­ ì„±ê³µ")
        else:
            log_message(f"ì›¹ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨ - ìƒíƒœ ì½”ë“œ {response.status_code}")
        return BeautifulSoup(response.content, 'html.parser')

    @log_decorator
    def extract(self):
        """
        HTMLì—ì„œ GDP í…Œì´ë¸”ì„ ì¶”ì¶œí•˜ê³  ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜.
        - 'wikitable' í´ë˜ìŠ¤ë¥¼ ê°€ì§„ í…Œì´ë¸”ì—ì„œ GDP ë°ì´í„°ë¥¼ ìˆ˜ì§‘.
        - í…Œì´ë¸”ì˜ ê° í–‰(<tr>)ì—ì„œ <td> í•­ëª©ì„ ì¶”ì¶œ.
        - ì¶”ì¶œí•œ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥.
        """
        table = self.soup.select_one('table.wikitable')  # 'wikitable' í´ë˜ìŠ¤ë¥¼ ê°€ì§„ í…Œì´ë¸” ì„ íƒ
        if table is None:
            log_message("âš ï¸ ë°ì´í„° í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. HTML êµ¬ì¡°ê°€ ë³€ê²½ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤.")
            raise ValueError("ë°ì´í„° í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        rows = table.select('tr') # <tr> íƒœê·¸ ì „ì²´ ì¶”ì¶œ

        # ì»¬ëŸ¼ ë§¤í•‘ì„ ìœ„í•œ ì„¤ì • (ìœ ì§€ë³´ìˆ˜ í¸ì˜ì„±)
        col_mapping = {
            'Country': 0,
            'GDP_USD_billion': 1,
            'Year': 2
        }
        
        # í…Œì´ë¸”ì˜ ê° í–‰ì—ì„œ êµ­ê°€, GDP, ì—°ë„ ì •ë³´ ì¶”ì¶œ
        df = pd.DataFrame([
            {
                'Country': cols[col_mapping['Country']].get_text(strip=True),
                'GDP_USD_billion': cols[col_mapping['GDP_USD_billion']].get_text(strip=True),
                'Year': re.sub(r'\[.*?\]', '', cols[col_mapping['Year']].get_text(strip=True)) # ì£¼ì„ ì œê±°
            }
            for row in rows
            if len(cols := row.find_all('td')) >= 3
        ])
        
        row_count = len(df)
        log_message(f"ì´ {row_count}ê°œ í–‰ ì¶”ì¶œë¨")  # ì´ ì¶”ì¶œëœ ë°ì´í„° ìˆ˜ ë¡œê·¸

        # Raw ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        df.to_json(RAW_DATA_FILE, orient='records', indent=4)
        file_size = os.path.getsize(RAW_DATA_FILE) / 1024  # KB ë‹¨ìœ„ë¡œ íŒŒì¼ í¬ê¸° ê³„ì‚°
        log_message(f"íŒŒì¼ ì €ì¥ ì™„ë£Œ: {RAW_DATA_FILE} ({file_size:.2f} KB)")
        return df

    @log_decorator
    def transform(self, df):
        """
        ë°ì´í„°í”„ë ˆì„ì„ ë³€í™˜í•˜ì—¬ í•„ìš”í•œ ë°ì´í„°ë§Œ ìœ ì§€í•˜ê³  GDP ë°ì´í„°ë¥¼ ê°€ê³µ.
        - 'World' ë°ì´í„°ë¥¼ ì œê±°.
        - 'â€”' ê¸°í˜¸ë¥¼ ê°€ì§„ ë°ì´í„°(ëˆ„ë½ëœ ê°’) í•„í„°ë§.
        - ì‰¼í‘œ(,) ì œê±° í›„ GDP ë°ì´í„°ë¥¼ ìˆ«ìë¡œ ë³€í™˜.
        - ì§€ì—­ ë§¤í•‘ íŒŒì¼ì„ ì´ìš©í•´ êµ­ê°€ë³„ë¡œ ì§€ì—­ ì¶”ê°€.
        """
        original_count = len(df)
        df = df[df['Country'] != 'World'] # 'World' ë°ì´í„° ì œê±°
        df = df[df['GDP_USD_billion'] != 'â€”'] # ëˆ„ë½ëœ ê°’('-') ì œê±°
        filtered_count = len(df)

        # GDP ë°ì´í„° ë³€í™˜ (ì‰¼í‘œ ì œê±° í›„ ìˆ«ìë¡œ ë³€í™˜)
        df['GDP_USD_billion'] = pd.to_numeric(df['GDP_USD_billion'].str.replace(',', ''), errors='coerce')
        df['GDP_USD_billion'] = (df['GDP_USD_billion'] / 1000).round(2)  # ë‹¨ìœ„ ì¡°ì • (ì–µ ë‹¬ëŸ¬ -> ì¡° ë‹¬ëŸ¬)

        # êµ­ê°€ë³„ ì§€ì—­ ë§¤í•‘ (JSON íŒŒì¼ì—ì„œ ì§€ì—­ ì •ë³´ ë¡œë“œ)
        with open(REGION_MAPPING_FILE, 'r') as f:
            region_mapping = json.load(f)
        df['Region'] = df['Country'].map(region_mapping)

        log_message(f"í•„í„°ë§ ì™„ë£Œ: {original_count - filtered_count}ê°œ í–‰ ì œê±°ë¨ (ì´ {filtered_count}ê°œ ë‚¨ìŒ)")
        unmapped = df['Region'].isna().sum()
        log_message(f"ì§€ì—­ ë§¤í•‘ ì™„ë£Œ: {unmapped}ê°œ êµ­ê°€ê°€ ë§¤í•‘ë˜ì§€ ì•ŠìŒ")  # ë§¤í•‘ë˜ì§€ ì•Šì€ êµ­ê°€ ìˆ˜ ê¸°ë¡
        return df

    @log_decorator
    def load(self, df):
        """
        ë³€í™˜ëœ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥.
        ì €ì¥ í›„ íŒŒì¼ í¬ê¸°ë¥¼ ë¡œê·¸ì— ê¸°ë¡.
        """
        df.to_json(PROCESSED_DATA_FILE, orient='records', indent=4)
        file_size = os.path.getsize(PROCESSED_DATA_FILE) / 1024  # KB ë‹¨ìœ„ë¡œ íŒŒì¼ í¬ê¸° ê³„ì‚°
        log_message(f"íŒŒì¼ ì €ì¥ ì™„ë£Œ: {PROCESSED_DATA_FILE} ({file_size:.2f} KB)")
        return len(df)

    @log_decorator
    def print_gdp_over_100b(self, df):
        """
        GDPê°€ 100B USD ì´ìƒì¸ êµ­ê°€ë¥¼ ì¶œë ¥.
        """
        gdp_over_100b = df[df['GDP_USD_billion'] >= 100]
        gdp_over_100b.index = range(1, len(gdp_over_100b) + 1)
        print("\nğŸŒ GDP 100B USD ì´ìƒ êµ­ê°€ ëª©ë¡:")
        print(tabulate(gdp_over_100b, headers='keys', tablefmt='grid'))
        log_message(f"GDP 100B ì´ìƒ êµ­ê°€ {len(gdp_over_100b)}ê°œ ì¶œë ¥ë¨")
        return len(gdp_over_100b)

    @log_decorator
    def print_region_avg_gdp(self, df):
        """
        ì§€ì—­ë³„ ìƒìœ„ 5ê°œ êµ­ê°€ì˜ GDP í‰ê· ì„ ê³„ì‚°í•˜ì—¬ ì¶œë ¥.
        """
        top_5_per_region = (
            df.sort_values('GDP_USD_billion', ascending=False)
            .groupby('Region')
            .head(5)
        )
        region_avg_gdp = (
            top_5_per_region.groupby('Region')['GDP_USD_billion']
            .mean()
            .round(2)
            .reset_index()
            .rename(columns={'GDP_USD_billion': 'Top 5 Avg GDP'})
            .sort_values('Top 5 Avg GDP', ascending=False)
        )
        region_avg_gdp.index = range(1, len(region_avg_gdp) + 1)
        print("\nğŸ“Š Regionë³„ ìƒìœ„ 5ê°œ êµ­ê°€ì˜ GDP í‰ê· :")
        print(tabulate(region_avg_gdp, headers='keys', tablefmt='grid'))
        log_message(f"Regionë³„ GDP í‰ê·  ê³„ì‚° ì™„ë£Œ (ì´ {len(region_avg_gdp)}ê°œ ì§€ì—­)")
        return len(region_avg_gdp)


def main():
    log_separator()
    etl = GDP_ETL(TARGET_URL)
    raw_df = etl.extract()
    transformed_df = etl.transform(raw_df)
    etl.load(transformed_df)
    etl.print_gdp_over_100b(transformed_df)
    etl.print_region_avg_gdp(transformed_df)


if __name__ == '__main__':
    main()