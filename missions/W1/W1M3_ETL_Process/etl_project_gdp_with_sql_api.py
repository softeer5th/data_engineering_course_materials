import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import json
import sqlite3
from tabulate import tabulate
from datetime import datetime
import os

# ìƒìˆ˜ ì„¤ì • (URL, íŒŒì¼ ê²½ë¡œ ë“±)
TARGET_URL = 'https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)'
YEAR = 2025
API_URL = f"https://www.imf.org/external/datamapper/api/v1/NGDPD?periods={YEAR}"
COUNTRIES_API_URL = "https://www.imf.org/external/datamapper/api/v1/countries"
REGION_MAPPING_FILE = 'data/all.json'
RAW_DATA_FILE = 'results/Countries_by_GDP_api.json'
PROCESSED_DATA_FILE = 'results/Countries_by_GDP_api_processed.json'
DB_FILE = 'sqliteDB/World_Economies.db' # SQLite DB íŒŒì¼ ê²½ë¡œ
LOG_FILE = 'log/etl_project_with_sql_api_log.txt'

# ë¡œê·¸ ê¸°ë¡ í•¨ìˆ˜
def log_message(message):
    """
    etl_project_log.txt íŒŒì¼ì— ë¡œê·¸ ë©”ì‹œì§€ë¥¼ ê¸°ë¡í•˜ëŠ” í•¨ìˆ˜.
    ì‹¤í–‰ ì‹œê°„ì„ í¬í•¨í•˜ì—¬ "time, log" í˜•ì‹ìœ¼ë¡œ ê¸°ë¡.
    """
    with open(LOG_FILE, 'a') as f:
        current_time = datetime.now().strftime('%Y-%B-%d-%H-%M-%S')
        f.write(f"{current_time}, {message}\n")

# ì‹¤í–‰ êµ¬ë¶„ì„  ì¶”ê°€ í•¨ìˆ˜
def log_separator():
    """
    ë¡œê·¸ íŒŒì¼ì— ì‹¤í–‰ êµ¬ë¶„ì„ ì„ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜.
    ìƒˆë¡œìš´ ì‹¤í–‰ì´ ì‹œì‘ë  ë•Œë§ˆë‹¤ ì‹¤í–‰ ì‹œê°„ì„ ëª…í™•í•˜ê²Œ êµ¬ë¶„í•´ì¤Œ.
    """
    with open(LOG_FILE, 'a') as f:
        f.write("\n" + "="*50 + "\n")
        current_time = datetime.now().strftime('%Y-%B-%d-%H-%M-%S')
        f.write(f"ğŸš€ New Execution at {current_time}\n")
        f.write("="*50 + "\n\n")

# ë¡œê·¸ ë°ì½”ë ˆì´í„° (í•¨ìˆ˜ ì‹œì‘/ì¢…ë£Œ ì‹œ ìë™ìœ¼ë¡œ ë¡œê·¸ ê¸°ë¡)
def log_decorator(func):
    """
    í•¨ìˆ˜ì˜ ì‹¤í–‰ ì‹œì‘ê³¼ ì™„ë£Œë¥¼ ìë™ìœ¼ë¡œ ë¡œê·¸ì— ê¸°ë¡í•˜ëŠ” ë°ì½”ë ˆì´í„°.
    ê° í•¨ìˆ˜ê°€ ì‹œì‘ë  ë•Œ 'ì‹œì‘', ì™„ë£Œë  ë•Œ 'ì™„ë£Œ'ë¡œ í‘œì‹œí•˜ë©°, ê²°ê³¼ê°€ ìˆ«ìì¸ ê²½ìš° ê²°ê³¼ ê°’ë„ ê¸°ë¡.
    """
    def wrapper(*args, **kwargs):
        log_message(f"{func.__name__} ì‹œì‘")
        result = func(*args, **kwargs)
        log_message(f"{func.__name__} ì™„ë£Œ: {result if isinstance(result, int) else 'Success'}")
        return result
    return wrapper

# GDP ETL (ì¶”ì¶œ, ë³€í™˜, ì ì¬) í´ë˜ìŠ¤
class GDP_ETL:
    """
    GDP ë°ì´í„°ë¥¼ ì¶”ì¶œ, ë³€í™˜, ì ì¬í•˜ëŠ” ETL íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤.
    ETL í”„ë¡œì„¸ìŠ¤ì˜ ê° ë‹¨ê³„ë¥¼ í•¨ìˆ˜ë¡œ ë‚˜ëˆ„ì–´ ê´€ë¦¬í•˜ë©°, ì›¹ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ê°€ê³µ í›„ ì €ì¥.
    """

    def __init__(self, url):
        self.url = url
        # self.soup = self._fetch_data()  # ì›¹ í˜ì´ì§€ì—ì„œ HTML ë°ì´í„° íŒŒì‹±

    # def _fetch_data(self):
    #     """
    #     ì›¹ í˜ì´ì§€ì—ì„œ HTMLì„ ìš”ì²­í•˜ì—¬ BeautifulSoup ê°ì²´ë¡œ ë°˜í™˜.
    #     ìš”ì²­ ìƒíƒœì— ë”°ë¼ ì„±ê³µ ë˜ëŠ” ì‹¤íŒ¨ ë©”ì‹œì§€ë¥¼ ë¡œê·¸ì— ê¸°ë¡.
    #     """
    #     response = requests.get(self.url)
    #     if response.status_code == 200:
    #         log_message("ì›¹ í˜ì´ì§€ ìš”ì²­ ì„±ê³µ")
    #     else:
    #         log_message(f"ì›¹ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨ - ìƒíƒœ ì½”ë“œ {response.status_code}")
    #     return BeautifulSoup(response.content, 'html.parser')
    
    # DB ì—°ê²° ë° ì¿¼ë¦¬ ì‹¤í–‰ (ê²°ê³¼ ë°˜í™˜ X) (ì‚½ì…, ìˆ˜ì •, ì‚­ì œ ìš©ë„)
    def execute_query(self, query, params=None):
        with sqlite3.connect(DB_FILE) as conn:
            cur = conn.cursor()
            if params:
                cur.execute(query, params)
            else:
                cur.execute(query)
            conn.commit()

    # DB ì—°ê²° ë° ì¿¼ë¦¬ ê²°ê³¼ ì¡°íšŒ (ê²°ê³¼ ë°˜í™˜ O) (ì¡°íšŒ ìš©ë„)
    def fetch_query(self, query, params=None):
        with sqlite3.connect(DB_FILE) as conn:
            if params:
                return pd.read_sql(query, conn, params=params)
            return pd.read_sql(query, conn)

    @log_decorator
    def extract(self, year=2025):
        """
        APIë¥¼ í†µí•´ 2025ë…„ GDP ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³  ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜.
        - IMF APIë¥¼ ì‚¬ìš©í•˜ì—¬ 2025ë…„ GDP ë°ì´í„°ë¥¼ ìˆ˜ì§‘.
        - JSON í˜•ì‹ì˜ ì‘ë‹µ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜.
        - ì¶”ì¶œí•œ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥.
        """       
        try:
            # API ìš”ì²­
            response = requests.get(API_URL)
            response.raise_for_status()
            log_message("API ìš”ì²­ ì„±ê³µ")
            data = response.json()    
        except requests.exceptions.RequestException as e:
            log_message(f"API ìš”ì²­ ì‹¤íŒ¨: {e}")
            raise ValueError("APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.") from e

        # JSON ë°ì´í„°ë¥¼ êµ­ê°€ ì½”ë“œì™€ GDP ê°’ì„ ì¶”ì¶œí•´ pandas DataFrameìœ¼ë¡œ ë³€í™˜
        try:
            values = data.get("values", {}).get("NGDPD", {})
            records = [
                {
                    'Country': country_code, # êµ­ê°€ ì´ë¦„
                    'GDP_USD_billion': gdp_data.get(str(YEAR), None), # GDP ê°’
                }
                for country_code, gdp_data in values.items()
            ]
            df = pd.DataFrame(records)
            row_count = len(df)
            log_message(f"ì´ {row_count}ê°œ í–‰ ì¶”ì¶œë¨")  # ì´ ì¶”ì¶œëœ ë°ì´í„° ìˆ˜ ë¡œê·¸
        except Exception as e:
            log_message(f"ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {e}")
            raise ValueError("ì‘ë‹µ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.") from e

        # Raw ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        df.to_json(RAW_DATA_FILE, orient='records', indent=4)
        file_size = os.path.getsize(RAW_DATA_FILE) / 1024  # KB ë‹¨ìœ„ë¡œ íŒŒì¼ í¬ê¸° ê³„ì‚°
        log_message(f"íŒŒì¼ ì €ì¥ ì™„ë£Œ: {RAW_DATA_FILE} ({file_size:.2f} KB)")
        return df

    @log_decorator
    def transform(self, df):
        """
        ë°ì´í„°í”„ë ˆì„ì„ ë³€í™˜í•˜ì—¬ í•„ìš”í•œ ë°ì´í„°ë§Œ ìœ ì§€í•˜ê³  GDP ë°ì´í„°ë¥¼ ê°€ê³µ.
        - GDP ë°ì´í„°ë¥¼ ì†Œìˆ«ì  ë‘˜ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼.
        - êµ­ê°€ ì½”ë“œì™€ ì§€ì—­(region)ì„ ë§¤í•‘.
        - êµ­ê°€ ì½”ë“œì™€ êµ­ê°€ ì´ë¦„ì„ ë§¤í•‘.
        - ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥.
        """

        df['GDP_USD_billion'] = df['GDP_USD_billion'].round(2)  # ì†Œìˆ«ì  2ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼

        try:
            # êµ­ê°€ ì½”ë“œì™€ ì§€ì—­ ë§¤í•‘
            with open(REGION_MAPPING_FILE, 'r') as file:
                region_mapping_data = json.load(file)
        except Exception as e:
            log_message(f"ì§€ì—­ ë§¤í•‘ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise ValueError("ì§€ì—­ ë§¤í•‘ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.") from e
        
        # êµ­ê°€ ì½”ë“œ(alpha-3) -> ì§€ì—­(region) ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        region_mapping = {entry['alpha-3']: entry['region'] for entry in region_mapping_data}

        # ë°ì´í„°í”„ë ˆì„ì— region ì¶”ê°€
        df['Region'] = df['Country'].map(region_mapping)

        # ë§¤í•‘ë˜ì§€ ì•Šì€ í•­ëª© ì œê±° (region ê°’ì´ ì—†ëŠ” í–‰)
        initial_count = len(df)
        df = df.dropna(subset=['Region']).copy()
        intermediate_count = len(df)
        removed_for_region = initial_count - intermediate_count
        log_message(f"ì§€ì—­(region) ë§¤í•‘ ì‹¤íŒ¨ë¡œ ì œê±°ëœ {removed_for_region}ê°œ í–‰")

        try:
            # êµ­ê°€ ì´ë¦„ê³¼ êµ­ê°€ ì½”ë“œ ë§¤í•‘ìš© ë°ì´í„° ìš”ì²­
            response = requests.get(COUNTRIES_API_URL)
            response.raise_for_status()
            log_message("êµ­ê°€ ì½”ë“œ ë°ì´í„° ìš”ì²­ ì„±ê³µ")
            countries_data = response.json()
        except requests.exceptions.RequestException as e:
            log_message(f"êµ­ê°€ ì½”ë“œ ë°ì´í„° ìš”ì²­ ì‹¤íŒ¨: {e}")
            raise ValueError("êµ­ê°€ ì½”ë“œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.") from e
        
        # êµ­ê°€ ì½”ë“œ -> êµ­ê°€ ì´ë¦„ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        country_mapping = {code: info['label'] for code, info in countries_data.get('countries', {}).items()}

         # ë§¤í•‘: êµ­ê°€ ì½”ë“œ -> êµ­ê°€ ì´ë¦„
        df['Country'] = df['Country'].map(country_mapping)

        # êµ­ê°€ ì´ë¦„ì´ ì—†ëŠ” í–‰ ì œê±° (ë§¤í•‘ ì‹¤íŒ¨)
        initial_count = len(df)
        df = df.dropna(subset=['Country']).copy()
        final_count = len(df)
        removed_count = initial_count - final_count
        log_message(f"ë§¤í•‘ë˜ì§€ ì•Šì€ {removed_count}ê°œ í–‰ ì œê±°ë¨")

        # ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
        df.to_json(PROCESSED_DATA_FILE, orient='records', indent=4)
        file_size = os.path.getsize(PROCESSED_DATA_FILE) / 1024  # KB ë‹¨ìœ„ë¡œ íŒŒì¼ í¬ê¸° ê³„ì‚°
        log_message(f"íŒŒì¼ ì €ì¥ ì™„ë£Œ: {PROCESSED_DATA_FILE} ({file_size:.2f} KB)")

        return df

    @log_decorator
    def load(self, df):
        """
        ë³€í™˜ëœ ë°ì´í„°ë¥¼ sqlite3 DBì— ì €ì¥.
        """
        # SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        with sqlite3.connect(DB_FILE) as conn:
            df.to_sql('Countries_by_GDP', conn, if_exists='replace', index=False)
            cur = conn.cursor()
            cur.execute("SELECT COUNT(*) FROM Countries_by_GDP")
            row_count = cur.fetchone()[0]
        log_message(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ: {row_count}ê°œ í–‰ ì €ì¥ë¨")
        return row_count

    @log_decorator
    def print_gdp_over_100b(self):
        """
        GDPê°€ 100B USD ì´ìƒì¸ êµ­ê°€ë¥¼ ì¶œë ¥.
        """
        query = """
        SELECT Country, GDP_USD_billion
        FROM Countries_by_GDP
        WHERE GDP_USD_billion >= 100
        ORDER BY GDP_USD_billion DESC;
        """
        df = self.fetch_query(query)

        df.index = range(1, len(df) + 1)
        print("\nğŸŒ GDP 100B USD ì´ìƒ êµ­ê°€ ëª©ë¡:")
        print(tabulate(df, headers='keys', tablefmt='grid'))
        log_message(f"GDP 100B ì´ìƒ êµ­ê°€ {len(df)}ê°œ ì¶œë ¥ë¨")
        return len(df)

    @log_decorator
    def print_region_avg_gdp(self):
        """
        ì§€ì—­ë³„ ìƒìœ„ 5ê°œ êµ­ê°€ì˜ GDP í‰ê· ì„ ê³„ì‚°í•˜ì—¬ ì¶œë ¥.
        """
        query = """
        SELECT Region, ROUND(AVG(GDP_USD_billion),2) AS "Top 5 Avg GDP"
        FROM (
            SELECT Country, Region, GDP_USD_billion,
                   ROW_NUMBER() OVER (PARTITION BY Region ORDER BY GDP_USD_billion DESC) AS rank
            FROM Countries_by_GDP
        )
        WHERE rank <= 5
        GROUP BY Region
        ORDER BY "Top 5 Avg GDP" DESC;
        """
        df = self.fetch_query(query)

        df.index = range(1, len(df) + 1)
        print("\nğŸ“Š Regionë³„ ìƒìœ„ 5ê°œ êµ­ê°€ì˜ GDP í‰ê· :")
        print(tabulate(df, headers='keys', tablefmt='grid'))
        log_message(f"Regionë³„ GDP í‰ê·  ê³„ì‚° ì™„ë£Œ (ì´ {len(df)}ê°œ ì§€ì—­)")
        return len(df)


def main():
    log_separator()
    etl = GDP_ETL(API_URL)
    raw_df = etl.extract()
    transformed_df = etl.transform(raw_df)
    etl.load(transformed_df)
    etl.print_gdp_over_100b()
    etl.print_region_avg_gdp()


if __name__ == '__main__':
    main()