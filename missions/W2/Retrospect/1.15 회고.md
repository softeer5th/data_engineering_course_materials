## 1/15 회고

### 오늘 한 일
- W2M5 추가요구사항: wordcloud의 작동 방법 (어떤 로직으로 시각화가 이루어지는지?)
- W2M5 추가학습거리: <Predicting Election Results from Twitter Using Machine Learning Algorithms> summary 읽고 소감 적기
- W2M6 기능 구현

### wordcloud 동작 원리 및 과정
1. 텍스트 분석 단계
    
    1-1. 텍스트 수집 및 전처리(Preprocessing)
    
    - 수집
    - 불용어 제거: ‘이’, ‘그’, ‘저’ 같은 의미가 약하거나 중복되는 단어 제거
    - 토큰화: 문장을 단어(토큰) 단위로 분리
    - 필요한 경우, 어근(lemma) 또는 원형을 기준으로 정규화
    
    1-2. 단어 빈도수 계산
    
    - 전처리된 단어 목록을 바탕으로, 각 단어가 몇 번 등장했는지 계산
2. 공간 배치 알고리즘(Layout)
    
    2-1. 단어 크기 결정
    
    - 가장 많이 등장한 단어를 가장 크게 표시하고, 빈도가 적은 단어는 상대적으로 작게 표시
    - 보통 최대/최소 폰트 크기를 정해두고, 해당 범위 안에서 선형 스케일링, 로그 스케일링 등을 적용
    
    2-2. 단어 배치 로직
    
    1. 초기 Canvas 설정
        - 2차원 평면 위에 단어를 배치할 공간을 마련
        - 가로x세로 해상도를 정하거나, 특정 마스크 이미지를 사용해서 단어가 배치도리 수 있는 영역을 미리 만들어 둠
    2. 가장 큰 단어부터 순서대로 배치
        - 빈도가 높은 단어부터 차례로 배치하기 시작
        - 보통 중앙을 시작점으로 삼는 경우가 많음 (가시성이 좋기 때문)
    3. 충돌 검사
        - 새로 놓을 단어가 기존에 배치된 단어들과 겹치지 않는지 확인
        - 단어가 차지하는 영역을 Bounding Box 등으로 계산하고, 겹치는 부분이 있는지 검사
        - 겹치는 경우, 조금 떨어진 위치로 이동시키거나 회전 각도를 바꾸어 다시 시도
    4. 위치 탐색 알고리즘
        - 한 번에 위치가 정해지지 않으므로, 특정한 규칙(스파이럴, 격자, 랜덤 등)을 따라 단어가 들어갈 수 있는 자리를 탐색
        1. 나선형 탐색 (대표적으로 사용됨)
            - 중앙에서부터 바깥으로 나선형 궤적을 그리며, 단어를 놓을 수 있는 빈 공간을 찾음.
            - (x,y) 좌표를 조금씩 변환시키면서 여기가 비어 있는가?를 검사함.
        2. 그리드 탐색
            - 화면을 격자 형태로 쪼개서 빈 칸을 찾음.
            - 충돌이 없으면 그 위치에 단어를 놓음.
        3. 랜덤 탐색
            - 가능한 범위 안에서 무작위 좌표를 골라 단어를 놓고, 충돌 검사 후 통과되면 확정.
3. 시각적 보정 및 스타일링
    - 색상, 폰트, 회전, 마스크 이미지 등등..

### <[Predicting Election Results from Twitter Using Machine Learning Algorithms](https://www.researchgate.net/publication/343310126_Predicting_Election_Results_from_Twitter_Using_Machine_Learning_Algorithms)> 소감

- sentiment analysis는 간단한 구현부터 프로젝트까지 많이 다뤄봤던 주제인데 해당 분석으로 이렇게 의미있는 결과를 뽑아낼 수 있다는 사실이 놀라웠다.
- 데이터 엔지니어링을 공부하는 학생으로서 해당 연구에서는 방대한 텍스트 데이터들을 유통하는 파이프라인을 어떻게 구성했을지 궁금했다.
- 연구에서는 SVM을 사용했지만, 최근 개발된 더 나은 딥러닝 모델(Transformer)을 활용한다면 정확도가 더 올라갈 수 있을지 궁금했다.
- 직접 sentiment analysis를 해봤을 때, 아무래도 영어에 모델을 적용했을 때랑, 한국어에 모델을 적용했을 때랑 정확도에 있어서 차이가 많이 났었는데 해당 연구를 우리나라에 맞게 적용을 시켰을 때 얼마나 높은 정확도를 보일지 궁금했다.

### W2M6 - Docker 이미지 AWS EC2에 배포하기

- W1에서 만들었던 Jupyter notebook 파일을 선택해서 실행할 수 있어야 됨.
    - COPY 명령어 통해서 Jupyter notebook 파일 /app 디렉토리에 복사해 놓는 방법
        
        → notebook 파일이 수정될 때마다 re-build를 해줘야 함. 배포용 파일에 적합
        
    - Volume 마운트
        
        ```bash
        docker run -it --rm -p 8888:8888 \
          -v $(pwd):/app \
          my-jupyter:latest
        ```
        
        → ipynb를 수정할 때마다 실시간으로 컨테이너 내부에도 변화 반영

- 아키텍처 안 맞는 이슈?
    → 로컬에서 AMD64 이미지를 빌드해서 해결
    → QEMU 에뮬레이터 켜줘야 함.

- 순서 정리

1.

```
docker build --platform linux/amd64 -t my-jupyter-repo .
```

2.

```
aws ecr get-login-password --region ap-northeast-2 | docker login --username AWS --password-stdin 537124951351.dkr.ecr.ap-northeast-2.amazonaws.com
```

3.

```
docker tag my-jupyter-repo:latest 537124951351.dkr.ecr.ap-northeast-2.amazonaws.com/my-jupyter-repo:latest
```

4.

```
docker push 537124951351.dkr.ecr.ap-northeast-2.amazonaws.com/my-jupyter-repo:latest
```

5.

```
docker pull <ECR_REPOSITORY_URI>:<TAG>
```

6.

```
docker run -p 8888:8888 <ECR_REPOSITORY_URI>:<TAG>
```

### Keep

ecr 아키텍처 문제에 직면했을 때 해결에만 급급해서 계속 막혔던 것 같은데, 한걸음 물러서서 처음 과정부터 어떤 부분 때문에 arm 아키텍처의 이미지가 ecr에 올라갔는지 천천히 고민해보니 생각보다 단순하게 답을 찾았다. 이런 방식의 사고가 앞으로의 학습에도 많은 도움을 줄 것 같다.

### Problem

ecr에 올린 이미지를 pull 하는 과정에서 아키텍처 불일치 이슈로 시간을 너무 오래 잡아 먹었다. 

### Try

wordcloud에 대해서 조사할 때, 나중에서야 wordcloud github 문서가 있다는 걸 알았는데, 기술의 github 레포를 들여다보면 원리에 대해 더 잘 이해할 수 있을 것 같다는 생각이 들었다.