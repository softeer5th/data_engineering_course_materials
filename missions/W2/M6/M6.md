## AWS free-tier EC2 생성하기
EC2 구성에 사용한 사용자 데이터:
```
#!/bin/bash
sudo apt update
sudo apt install apt-transport-https ca-certificates curl software-properties-common
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu focal stable"
sudo apt update
```

## Docker Image 생성하기
이미지 생성에 사용한 Dockerfile:
- EC2 inbound 규칙을 통해 22(SSH), 8888(jupyter) port 개방
- W1, W2 파일 실행에 필요한 기본 라이브러리 사전 설치
- 작업 폴더 공유를 위해 /workspace 폴더 생성
- EC2는 브라우저를 쓸 수 없으니 --no-browser 설정
- 이미지 생성 시:
  * 어떤 OS를 선택해야 할까요? --> 리눅스 기반 대부분의 환경에 호환성이 좋은 **Ubuntu**
  * 어떤 소프트웨어를 설치해야 할까요? --> python, jupyterlab, 파일 구동에 필요한 라이브러리
  * 어떤 화일을 담아야 할까요? --> W1, W2 folder
    * COPY 명령어에서 빌드 컨텍스트 내의 경로를 사용해야 하므로, <br>빌드 컨텍스트를 기준으로 상대 경로를 지정해야 합니다.
```
FROM ubuntu:24.04

RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    curl \
    && apt-get clean

COPY W1 /workspace/

COPY W2 /workspace/

RUN python3 -m pip config set global.break-system-packages true

RUN pip3 install jupyterlab

RUN pip3 install numpy pandas matplotlib beautifulsoup4 wordcloud

WORKDIR /workspace

EXPOSE 8888

CMD [ "jupyter-lab", "--ip=0.0.0.0", "--port=8888", "--no-browser", "--allow-root" ]
```

## EC2에서 이미지 pull
```
docker pull vs501kr/softeer:jupyterlab_v3
```

## run.sh 파일을 이용해 컨테이너 접속 시 jupyterlab 접속 url 생성
```
docker run -it --rm \
  -p 8888:8888 \
  -v /home/ubuntu/workspace:/workspace \
  vs501kr/softeer:jupyterlab_v3 \
  bash -c "jupyter-lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root & 
  sleep infinity && 
  curl -s http://127.0.0.1:8888 | grep -Eo 'http://127.0.0.1:8888/lab\\?token=[^ ]*'"
```

### workspace가 EC2, container간에 연결되었으므로 폴더에 접근해 파일을 실행 가능합니다.
-----------
# M6 팀 활동
-----------
## Docker를 사용하는 이유가 뭘까요?
- 내 컴에선 되던데요? <— 차단
- 시스템이 돌아가는 데 필요한 환경을 구성하고 이를 배포 가능
- 같은 컨테이너를 사용하는 컴퓨터는 모두 동일한 실행 조건을 확보
- 가상머신 대비 가볍고 커널이 분리된다, 가볍다
- 도커파일이나 컨테이너 config로 간편설정 가능
- 각 컨테이너 별 독립된 환경으로 특정 라이브러리나 버전 변경이 다른 프로그램에 영향을 미치는 상황 사전 방지
- 롤백?이 편하다 
    - 업뎃해서 안되면 이전 이미지로 하면 됨
- 컴퓨팅 자원 scale in/out이 간단함 -> docker run에 아래의 명령어를 붙인다
  - --cpus, --cpu-shares 등으로 cpu 리소스 할당 제어
  - --memory, --memory-swap 메모리 사용량 제어
  - --blkio-weight 디스크 I/O할당량 제어
## 어떤 점은 더 불편한가요?
- 사전 지식 필요
- 이미지 만들고 컨테이너 실행 파일 만드는 과정
    - 이미지 경량화 과정에서 무엇을 넣고 뺄지 
    - 실행 sh, yaml등을 만드는 과정에서 어떻게 하면 최대한 추가 작업 없이 바로 원하는 환경(ex jupyterlab 링크 생성)을 얻을 수 있는지에 대한 고민
        - 사실 sh, yaml은 이미지를 바꾸는 것도 아니라서 그리 큰 문제가 되진 않을 것 같다.
- 도커 내부 환경은 GUI가 지원되지 않으므로 CLI환경에 익숙하지 않다면 그 자체로 불편함을 안고 간다
- 아키텍쳐 별 빌드 옵션이 상이
    - Mac Silicon은 arm64, EC2 인스턴스는 amd64로 아키텍쳐가 달라 배포 시 유의해야 한다

## 여러 EC2에 여러 컨테이너를 배포하는 상황에 대해 추천하는 최적의 방법:
1. **ECR과 ECS의 결합**:
    * ECR에 이미지를 푸시하고, ECS의 Task Definition을 통해 컨테이너 정의를 관리합니다.
    * ECS Fargate를 활용하면 EC2 인스턴스를 관리할 필요 없이 서버리스 방식으로 컨테이너를 실행할 수 있어 관리가 더욱 간편해집니다. <br>Fargate는 서버를 관리할 필요 없이, 컨테이너만 배포하면 되므로 운영 부담을 크게 줄여줍니다.
2. **배포 자동화**:
    * AWS CodePipeline과 CodeBuild를 사용하여 CI/CD 파이프라인을 구축하고, Docker 이미지의 빌드 및 배포를 자동화하는 방법을 추천합니다. <br>이를 통해 코드 변경 시 자동으로 이미지가 빌드되고 ECR에 푸시되며, ECS에서 자동으로 컨테이너를 배포할 수 있습니다.
    * Terraform이나 CloudFormation을 사용하여 인프라를 코드화하고, 배포 및 환경 설정을 자동화할 수 있습니다
