# 1/20 회고

## 수업 내용 정리

## Hadoop

### Hadoop Components

- HDFS  : Storage Layer
- Hadoop Yarn : Resource Management Layer
- Hadoop MapReduce : Application Layer

### Hadoop Architecture

각각의 레이어 별로 Master-Slave 관계가 따로따로 있다.

Master Node : Name Node(Storage Layer), ResourceManager(Resource Management Layer)

Slave Node : DataNode, NodeManager

### Assumptions and Goals of HDFS

- Hardware Failure
- Streaming Data Access
- Large Datasets
- **Simple Coherency Model**
    
    → 즉, **HDFS에 한번 저장된 데이터는 수정할 수 없고, 읽기만 가능하게 하여 무결성을 지킴**
    
- “Moving Computation is Cheaper than Moving Data”
- Portability Across Heterogeneous Hardware and Software Platforms

### Simple Coherency Model

- WORM(write-once-read-many)
- high throughput data access가 가능해진다
- 대신 스토리지 용량 효율을 포기
- 오히려 로그 데이터는 permanent 하기 때문에 적합할수도
- mapreduce application이나 web crawler application에 완벽히 맞는 모델

### Moving Computations is Cheaper than Moving Data

- 데이터가 분산되있음을 전제. (data parrelism)

### Commodity Hardware (싸구려 머신)

- Hardware 가격이 logimetric하게 비싸지기 때문

### NameNode & DataNode

NameNode : metadata를 저장함

DataNode : actual business data를 저장함

### Data Locality

Data Local : data와 map이 같은 데이터 안에 있음

Rack Local : 같은 rack 안에 있으나 데이터와 같은 위치에 있는 map이 리소스가 묶여 있을 때

Different Rack

## YARN

### Yet Another Resource Manager

- resource management 와 job scheduling/monitoring을 각자의 daemon으로 나눔.

Application Master가 하나 죽었다. → 누가 죽었는지 어떻게 알래?

### ResourceManager, NodeManager, ApplicationMaster

ResourceManager : ultimate authority

NodeManager : per-machine framework agent

ApplicationMaster : per-application

## Hadoop MapReduce

HDFS Split → Map → Shuffle & Sort → Reduce

## 오늘 한 일

- W3M1 문서화 부분 제외하고 구현 완료

### Keep

팀원에게 직접 참고했던 블로그 링크와 방법을 공유해주면서 설명하는 데 시간을 썼고, 그 시간이 나도 학습에 도움이 됐던 시간이었다.

### Problem

오늘같이 구현의 난이도가 조금만 올라가도 디버깅에 급급해 구현 과정을 문서화 해놓는 걸 잊는 듯 하다.

### Try

작업과 병행하는 문서화 과정에 좀 더 신경을 많이 써야 할 것 같다.