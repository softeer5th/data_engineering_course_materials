{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "from docker.models.containers import Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Container: 331b2565616b>,\n",
       " <Container: d80e7ec10d30>,\n",
       " <Container: c4f8aae5c4ae>,\n",
       " <Container: a3153ae8b4a2>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = docker.from_env()\n",
    "containers: list[Container] = client.containers.list()\n",
    "containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_prefix = ['hdfs', 'getconf', '-confKey']\n",
    "hadoop_prefix = ['hdfs', 'getconf', '-confKey']\n",
    "yarn_prefix = ['hdfs', 'getconf', '-confKey']\n",
    "\n",
    "hdfs_attr = ['fs.defaultFS', 'hadoop.tmp.dir', 'io.file.buffer.size', 'dfs.replication', 'dfs.blocksize','dfs.namenode.name.dir']\n",
    "hadoop_attr = ['mapreduce.framework.name', 'mapreduce.job.tracker', 'mapreduce.task.io.sort.mb']\n",
    "yarn_attr = ['yarn.resourcemanager.address', 'yarn.nodemanager.resource.memory-mb', 'yarn.scheduler.minimum-allocation-mb']\n",
    "\n",
    "def checkAttr(container:Container, command_prefix:list, attr_list:list):\n",
    "    for attr in attr_list:\n",
    "        cmd = command_prefix + [attr]\n",
    "        code, output = container.exec_run(cmd)\n",
    "        msg = output.decode('utf-8').strip()\n",
    "        if code == 0:\n",
    "            print(f'{cmd} -> {msg}')\n",
    "        else:\n",
    "            print(f'검사 실패: {code}')\n",
    "            print(f'메시지: {msg}')\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker-3\n",
      "worker-2\n",
      "master\n",
      "['hdfs', 'getconf', '-confKey', 'fs.defaultFS'] -> hdfs://master:9000\n",
      "['hdfs', 'getconf', '-confKey', 'hadoop.tmp.dir'] -> /tmp/hadoop-root\n",
      "['hdfs', 'getconf', '-confKey', 'io.file.buffer.size'] -> 4096\n",
      "['hdfs', 'getconf', '-confKey', 'dfs.replication'] -> 3\n",
      "['hdfs', 'getconf', '-confKey', 'dfs.blocksize'] -> 134217728\n",
      "['hdfs', 'getconf', '-confKey', 'dfs.namenode.name.dir'] -> file:///usr/local/hadoop/hdfs/namenode\n",
      "['hdfs', 'getconf', '-confKey', 'mapreduce.framework.name'] -> yarn\n",
      "검사 실패: 255\n",
      "메시지: Configuration mapreduce.job.tracker is missing.\n",
      "['hdfs', 'getconf', '-confKey', 'mapreduce.task.io.sort.mb'] -> 100\n",
      "['hdfs', 'getconf', '-confKey', 'yarn.resourcemanager.address'] -> master:8032\n",
      "['hdfs', 'getconf', '-confKey', 'yarn.nodemanager.resource.memory-mb'] -> -1\n",
      "['hdfs', 'getconf', '-confKey', 'yarn.scheduler.minimum-allocation-mb'] -> 1024\n",
      "worker-1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for container in containers:\n",
    "    print(container.name)\n",
    "    if container.name == 'master':\n",
    "        checkAttr(container, hdfs_prefix, hdfs_attr)\n",
    "        checkAttr(container, hadoop_prefix, hadoop_attr)\n",
    "        checkAttr(container, yarn_prefix, yarn_attr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "softeer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
