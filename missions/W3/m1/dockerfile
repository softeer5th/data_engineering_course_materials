# ubuntu : base image
FROM ubuntu:20.04

# apt settings
RUN apt-get update
RUN apt-get install -y sudo

# ENV setting
ENV HADOOP_HOME=/usr/local/hadoop
ENV PATH=$PATH:$HADOOP_HOME/bin
ENV JAVA_HOME=/usr/lib/jvm/java-8-openjdk-arm64
ENV PATH=$JAVA_HOME/bin:$PATH

# java get
RUN apt-get install -y openjdk-8-jdk ssh

# hadoop install
COPY /data/hadoop-3.4.1.tar.gz /hadoop-3.4.1.tar.gz
RUN tar -zxf hadoop-3.4.1.tar.gz && \
    mv hadoop-3.4.1 $HADOOP_HOME && \
    rm hadoop-3.4.1.tar.gz

# ssh setting
RUN ssh-keygen -t rsa -f ~/.ssh/id_rsa -P ''; \
    cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys; \
    chmod 400 ~/.ssh/id_rsa; \
    echo "Host *\n  StrictHostKeyChecking no" > ~/.ssh/config;

# Hadoop settings
RUN echo "export JAVA_HOME=$JAVA_HOME" >> /usr/local/hadoop/etc/hadoop/hadoop-env.sh; \
    echo "export HDFS_NAMENODE_USER=root" >> /usr/local/hadoop/etc/hadoop/hadoop-env.sh; \
    echo "export HDFS_DATANODE_USER=root" >> /usr/local/hadoop/etc/hadoop/hadoop-env.sh; \
    echo "export HDFS_SECONDARYNAMENODE_USER=root" >> /usr/local/hadoop/etc/hadoop/hadoop-env.sh;\
    echo "export YARN_RESOURCEMANAGER_USER=root" >> /usr/local/hadoop/etc/hadoop/hadoop-env.sh; \
    echo "export YARN_NODEMANAGER_USER=root" >> /usr/local/hadoop/etc/hadoop/hadoop-env.sh;

# Hadoop configurations
COPY ./core-site.xml $HADOOP_HOME/etc/hadoop/core-site.xml
COPY ./hdfs-site.xml $HADOOP_HOME/etc/hadoop/hdfs-site.xml
COPY ./mapred-site.xml $HADOOP_HOME/etc/hadoop/mapred-site.xml

# port forwarding
EXPOSE 9870 9000 9864 8088 8042 9868 10020 19888

# Format the Namenode
#RUN $HADOOP_HOME/sbin/start-dfs.sh
#RUN $HADOOP_HOME/sbin/start-yarn.sh
CMD ["sh", "-c", "service ssh start; $HADOOP_HOME/bin/hdfs namenode -format; $HADOOP_HOME/sbin/start-dfs.sh && $HADOOP_HOME/sbin/start-yarn.sh && bash"]
