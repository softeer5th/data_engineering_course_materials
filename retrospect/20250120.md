## 리뷰
  ### 데일리 스크럼
  
  * 오늘 할 일: 
      1. W1M3 리팩토링 (O)
      2. W2M6 스왑메모리 추가 (X)
      3. M5 진행 (X)
      + 멀티프로세싱 문제 해결 (O)  


### **W1M3 리팩토링**
- etl_project_gdp.py 파일을 리팩토링하고, pandas를 활용한 transform 처리도 추가
- analyzer 모듈을 추가하고, 데이터를 분석하는 로직 추가


### Hadoop Single Node Cluster
- Hadoop Single Node Cluster on Docker.

W3M1 요구사항 분석:

```bash
  docker pull julienlau/hadoop-single-node-cluster:3.3.3

  1. 자동으로 모든 하둡 서비스가 시작되어야 한다.
  2. HDFS는 호스트 네트워크와 연결하여 hdfs를 사용할 수 있게끔 한다.
  3. HDFS는 웹 인터페이스로 접근할 수 있어야 한다.
  4. 데이터는 컨테이너가 재시작되어도 보존되어야 한다. (docker volume 사용): 이거 실제로 되는지 체크 필요.
  5. HDFS에 디렉토리 만들고, 텍스트 파일 쓰고, HDFS에서 읽어올 수 있는지 확인
  6. 문서화: 각 명령에 대한 명확한 설명이 있어야 함. 그리고 어떻게 HDFS 명령을 실행시키는지 기본적인 것도 작성 필요.
  7. hadoop configure: core-site.xml, hdfs-site.xml, mapred-site.xml, yarn-site.xml을 설정. 하둡 환경변수 설정. 
  8. hdfs namenode 포맷 (하드디스크 처음 시작시와 같음)
  8. 제출: Dockerfile, README.md (instruction), xml 파일들. 

```

1. localhost:9870 접속해서 확인해보기: 네임노드 웹 인터페이스
2. localhost:9864 접속해서 확인해보기: 데이터노드 웹 인터페이스
3. localhost:8088 접속해서 확인해보기: 리소스매니저 웹 인터페이스
4. localhost:9000 접속해서 확인해보기: HDFS 웹 인터페이스
Secondary namenode는 포트가 9868이다.


dfs에 디렉토리 생성하기:
```bash
  hdfs dfs -mkdir /user
  hdfs dfs -mkdir /user/hduser
```

input 디렉토리 생성하고, 파일 복사하기:
```bash
  hdfs dfs -mkdir input
  hdfs dfs -put $HADOOP_HOME/etc/hadoop/*.xml input
```

파일 읽기:
```bash
  hdfs dfs -cat input/*.xml
```

호스트에서 도커 컨테이너의 hdfs dfs put으로 데이터 넣기

1. WebHDFS REST API 사용:
```xml
<!-- hdfs-site.xml에 추가 -->
<property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
</property>
```

1. docker exec 사용
```bash
# 1. 호스트에서 도커 컨테이너로 파일 전송
docker cp myfile.txt container_name:/home/hduser/

# 2. 컨테이너에 접속하여 HDFS로 파일 업로드
docker exec container_name hdfs dfs -put /home/hduser/myfile.txt /user/hduser/

# 또는 한 번에 실행
docker exec container_name hdfs dfs -put /home/hduser/myfile.txt /user/hduser/myfile.txt
```

### Docker
- Docker 디버깅은 docker desktop에서 exec을 확인하거나 files를 확인하는 방법이 있다.
- volume을 생성하고, mount를 하면 컨테이너가 재시작되어도 데이터(HDFS)가 보존된다.

## Hadoop 이해하기
### Hadoop HDFS
- Hadoop은 HDFS, MapReduce, YARN
- HDFS 관점: 파일 시스템, 블록, 네임노드(master), 데이터노드(slave)
- replication을 다른 노드에 하여 hardware fault를 해결한다 (redundancy)
- 네임노드는 replication을 최대한 보장하기 위해 데이터 노드가 죽으면 바로 다른 데이터 노드에 복사한다.
- Simple Coherency Model: WORM(Write Once Read Many) 모델. 파일은 한 번만 쓰고 여러 번 읽는다.
    - read lock, write lock 필요가 없다
    - 데이터 변경에 대한 반영은 하지 않는다고 가정. 대신 throughput을 높인다.
    - 사용법 ex) redis로 실시간은 인메모리로 처리하고, HDFS는 로그로 저장한다.

- “Moving Computation is Cheaper than Moving Data” 
- => **Data Locality**: 처리는 데이터가 있는 곳에서 최대한 처리한다. 데이터 분산과 data parallelism이 전제되어야 의미가 있다.
- 빠른 순서: data node local -> rack local -> different rack
- Commodity Hardware: 저렴한 하드웨어를 사용하여 scale out한다.

### Hadoop YARN
### 모두 각 역할이 분명하게 나뉘어져 있다.
- Yet Another Resource Negotiator
- 리소스 매니저: 클러스터 하드웨어 리소스를 관리한다. 클러스터의 리소스를 어떻게 할당할지 결정한다. 네임노드에 위치.
- 노드 매니저: 각 노드의 하드웨어 리소스를 관리한다. 데이터 노드에 위치

### Job scheduling / monitoring
- Application Master: 애플리케이션 당 하나로, 데이터 노드 단에 위치한다. 애플리케이션 컨테이너 실행을 관리한다. 끝나면 리소스를 반환한다. 죽으면 scheduler가 다시 실행하도록 명령을 한다.
- Application Manager: 네임노드에 존재하며, Job의 유효성만 체크하고, scheduler에게 전달한다.
- scheduler: Job을 실행할 노드를 결정한다. Application Master의 재실행 등도 관리한다.

### Hadoop MapReduce
- MapReduce는 데이터를 처리하는 프레임워크이다.
- reliable, fault-tolerant, map, shuffle, sort, reduce 등의 기능을 제공한다.
- data parallelism이 전제되어야만 한다.
- data locality를 최대한 활용해야만 한다.
- HDFS가 아닌 local disk에 중간 결과들을 저장한다.
- Input과 Output은 HDFS에 저장한다.

---

### Keep:계속 유지
  - 에러 메세지와 내용을 확인해보고, 요구사항을 천천히 한 번에 확인하여 처리하자 (AI에게는 적당히 물어보자)
  - 아이디어를 꾸준히 조금씩 내도록 하자 (단, 금전적 가치가 있어야 한다)
  - 다른 분들에게 도움을 줄 수 있으면 주저하지 말자
  - Hadoop의 아키텍처와 각 역할, 그리고 필요성을 이해하고 암기하자
  - 다른 사람이 만든 것을 적극적으로 사용하고, 이해하자

---

### Problem: 문제가 발생한 행동
  - 오늘 스스로 왜인지 모르지만 조금 예민했던 것 같다. 웃으면서, 즐겁고 화이팅 넘치게 하자

---
### Try: 다음 번에 새롭게 시도했으면 좋을 행동
  - 목표에 대한 시간 설정을 하면서, 시간을 맞추려고 노력하자