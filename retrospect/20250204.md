## 리뷰
  ### 데일리 스크럼

  ### AWS
  - Region, AZ(물리적으로는 여러 데이터센터가 밀접하게 합쳐진 개념), Edge Location(캐싱 많이 필요한 static file, Lambda Edge.) 설명
  - VPC, Subnet, Route Table, Internet Gateway, Security Group(인스턴스 단위 보안 규칙. 인바운드, 아웃바운드 통일. SG chaining도 가능.), NACL(Network Access Control List. Inbound, Outbound 각각 설정. 서브넷 단위)
  - Account(AWS 계정), User(사용자), Role(역할. 임시 및 인스턴스에게 권한 부여), Policy(정책. 권한 부여)
  - 권한 우선 순위는 무조건 Deny가 높다. (User, Group에서 Allow, Deny가 있을 때, Deny가 높다.)
  - Role은 권한을 덮어쓰기한다. (User, Group에서의 권한은 Role이 있는 동안은 초기화된다)

  ### M2

  - Outlier를 취급할 때, 빅 데이터인 경우 이상치를 찾는 것 자체가 어렵다.
  - ex) trip_distance를 단순히 outlier를 제거하는 IQR, Z-score로 제거하면, 의미있는 데이터가 손실될 수 있다. 멀리 가는 고객을 중요 고객이라고 하고 하는 시나리오 상에서 중요 고객을 많이 유치하려고 하는 목적이라면 정작 중요 고객들이 이상치가 되어버리는 셈이다(평균은 3.2, 표준편차는 4이고, 1/4분위, 3/4분위가 1, 3.1라면, IQR 사용 시에는 0~6.2의 데이터만 반영되고, 3시그마 범위를 사용하면 3.2+4*3=15.2까지의 데이터만 반영된다).
  - 빅 데이터인 경우 시각화 자체가 어렵기에, 자체적으로 구간을 만들고 큰 데이터의 변환은 spark로 하면서 시각화는 판다스로 변환하여 진행하는 EDA를 하여 이상치를 찾아내는 방법을 사용하는 것이 더욱 중요해 보인다.
  
  **ps.DataFrame**
  - pandas on spark API의 DataFrame.
  - pandas와 호환되는 API를 사용하지만, 호환이 안되는 것도 존재한다.

  **to_spark()**
  - spark DataFrame이기에 sparkSQL 등 다양한 기능을 사용할 수 있다.
  - ex) SQL의 임시 뷰 테이블 생성 및 사용.
  
---

### Keep:계속 유지
  - 지속적인 프로토타이핑으로 문제를 구체화시키자
  - "누구의" 문제인지를 알기 위하여 관련 정보를 계속해서 찾아보자
  - 질문을 두려워하지 말고, 모르는 것이 있다면 질문하자

---

### Problem: 문제가 발생한 행동
  - X

---
### Try: 다음 번에 새롭게 시도했으면 좋을 행동
  - "누구"를 설정하고, 다시 프로토타이핑하고, "누구"를 구체화하고 등 iteration을 계속 가져가자