## 리뷰
  ### 데일리 스크럼
  
  ### 남은 시간 어떻게 develop 시킬까?
  1. 데이터 집계해서 최종지표 명확히 하기
  2. 최종지표 바탕으로 작가 선정 기준 정하기
  3. 최종지표 빠르게 뽑아보기

  ### 작가 세우는 기준
  - 1년에 2차 시장에 나오는 작품 개수 10개 이상
  - 편향성 통일 - 작가 그룹
    - 1990년 이전에 돌아가신 작가. 백인 남자.
  - 1억 ~ 10억 사이의 작품 존재
  - 경매 내역 100개 이상

  ### 최종 지표
  - 작가 이름
  1. 올해 몇 개 정도 작품이 나올 것 같고, 1년 후에 몇 퍼센트 수익이 나올 것 같다.
  2. 미니멈 예상 투자 액수 - 작가 자체를 알아볼 시간을 단축
  3. 작가가 잘하는 장르 3개
  
  ### 백그라운드 지표
  - 1번 지표: 
    - 연도별 작품 평균 가치 및 상승률
    - 연도별 작품이 나온 개수
  - 2번 지표:
    - 작가 작품들의 가격 하위 80프로를 미니멈 예상 투자 액수로 설정
  - 3번 지표:
    - 작품 기법별로 groupby해서 비싼 평균 가격 상위 3개
    - 재료들을 보고 대분류로 묶어내기
  
  ### 문제점
  **문제: 작품별 id를 설정할 수가 없다.**
    - 작가, 제목, 높이, 너비, 제작년도를 id로 사용한다고 해도 중북이 많다.
    - 여러 작품이 동시에 경매로 나온다.
    - 그림별로 식별해주는 AI가 필요한데, 이건 남은 시간으로는 불가능하다.
  **해결: 1년에 경매가 많이 이루어지는 작가(피카소)를 선정하여 경매 낙찰 가격으로 가격 평균 가치 상승률을 계산한다.**

  **문제: 점점 떨어지는 그래프처럼 보이고, 2024년은 가격이 폭락하였는데, 판화가 많이 나온 것이 문제로 보인다.**
  **해결: 판화를 제외하고, 그림만 남겨서 확인해본다**
  
  ### PySpark
  공식 문서: ps.options.compute.max_rows
  - 1000행 이하라면 driver로 데이터를 가져와서 pandas API로 처리.
  - 1000행 이상이면 pySpark로 처리
  
  ### JVM 메모리 제한
  - 계속 spark에서 heap 메모리가 부족하다는 에러가 발생했다.
  - macOS에서 JVM이 차지하는 메모리가 1.4GB로 제한되어 있었다.
  - 이를 해결하기 위해서는 `export _JAVA_OPTIONS="-Xmx8g"`를 사용하고 재부팅하면 된다.

  ### JOIN
  - JOIN 연산은 부하가 큰 연산이다.
  - 그 전에 날씨 데이터셋을 보고, JOIN 조건이 잘 되는지 확인해야만 한다.
  
  ### SQL 날짜 연산
  - date_format 함수를 사용하면 날짜를 원하는 형식으로 바꿀 수 있다.
    - `date_format('2022-01-31:00:11:22', 'yyyy-MM-dd')` -> `2022-01-31`
  - **BETWEEN 연산자를 사용할 시에는 반드시 끝이 포함되지 않는다는 것에 주의하자.**
    - `date_format('2022-01-31:01:11:22', 'yyyy-MM-dd:HH') BETWEEN '2022-01-01' AND '2022-01-31'` -> `False`
  
  ### 날씨 API
  - ISD 데이터셋을 사용하면, 1900년대부터 현재까지의 날씨 데이터를 1시간 단위로 제공한다.
  - FM-15만 사용하면 된다.

---

### Keep:계속 유지
  - 팀프로젝트를 할 때, 계속 마일스톤을 설정하고 실행하고 있다.

---

### Problem: 문제가 발생한 행동
  - 개인 미션 진도가 늦어지고 있다.

---
### Try: 다음 번에 새롭게 시도했으면 좋을 행동
  - 개인 미션을 덜 디테일하게 하면서, 일단 끝내자.