## 리뷰
  ### 데일리 스크럼
  - 프로토타이핑 결과 공유: 의미있는 결과를 내기는 쉽지 않았음.
  - 

  ### Spark Job
  - "특정" 데이터에 맞는 최적화.
  - 데이터의 크기, 뭘 처리할 지에 대해 달라진다.

  ### computation efficiency
  - 파티션 단위 개념.
  - Dataframe: structured. 스트리밍은 아님.
  - RDD: unstructured. 텍스트 스트림, raw data 등.
  
  ### parquet:
  - columnar storage -> column wise 저장.
  - 셔플에 효과적인 압축 포맷: snappy, LZ4 등.
  - RowGroup도 지정 하능.
  - WORM -> 조회가 빠름.
  
  ### Spark Memory
  - JVM 메모리 관리: LRUCache: 최근에 사용한 것을 메모리에 올려놓음.
  - 가본 메모리: 300MB.
  - 메모리 overhead: 384MB와 spark.memory.fraction의 10% 중 max 값.
  - spark.memory.fraction: 0.6 -> 60%.
  - spark.memory.storageFraction: 0.5 -> 50%. (spark.memory.fraction 중 50%만 사용한다는 것. RDD, Dataframe 등)
  - user memory: 1 - spark.memory.fraction.
  
  - 이래서 처음에 작업 시에 OOM 발생했던 것.
  - 1.4GB = 메모리 오버헤드 (384MB) + 가본 메모리 (300MB) + spark.memory.fraction ((1.4 - 0.7 )* 0.6 = 420MB) + spark.memory.storageFraction ((1.4 - 0.7) * 0.6 * 0.5= 210MB)
  - 그러니 storage 부분이 210MB, executor 부분이 210MB가 되어서 OOM이 발생했던 것. 서로 공유가 가능해도 420MB라는 작은 메모리.
  
  ### Query Optimization
  - sortWithinPartitions: 파티션 내에서 정렬. no shuffle.
  - repartitionByRange: range로 파티션을 나눔. 내부적으로 sortWithinPartitions를 사용.
  - window function 사용: filtering과 aggregation을 하여, 셔플을 없애고 결과만 가져올 때 합쳐짐.
  - broadcast join: 작은 테이블을 큰 테이블에 join할 때 사용. 큰 테이블을 모든 executor에 복사해서 join.
  - splitting: 데이터 skewing을 방지하기 위해 데이터를 나눔.
  - salting: 데이터를 나누는데 개수를 보고 salt를 추가. GroupBy를 할 때 데이터 skewing을 방지.
  - early filter: 필터링을 미리 하면, 데이터를 줄일 수 있음!
  
  ### Cache vs Persist vs Checkpoint
  - cache: 메모리에 올림. lineage를 가지고 있음. **안쓰면 삭제하자!**
  - persist: 메모리, 디스크에 올림. 디스크 사용 시, 다른 Job에서 공유 가능. 디버깅 용도 가능. 노드가 죽으면 다시 읽을 수 없음. lineage를 가지고 있음.
  - checkpoint: HDFS 올림. 실패를 대비. 디버깅 용도 사용 가능. lineage를 가지고 있지 않음.
  

  ### 문제 정의
  - 더욱 급박한, 고통이 큰 문제찾기.
  - 비상상황 시 대처 등.
---

### Keep:계속 유지
  - 예시를 계속 들고, 유즈케이스를 바탕으로 설명하자.
  - 열정적인 토의로 서로의 싱크를 맞추고, 방향을 일치시키자.

---

### Problem: 문제가 발생한 행동
  - X

---

### Try: 다음 번에 새롭게 시도했으면 좋을 행동
  - X
