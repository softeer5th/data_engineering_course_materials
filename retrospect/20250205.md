## 리뷰
  ### 데일리 스크럼

  **오늘 할 일**
  오전: 미션 마무리
  오후: 미팅 및 프로토타이핑

  ### M2
  - 실행계획 확인하기: explain()에서 모드에 따라 다르다.
  - RDD 연산보다 DataFrame이 빠른 이유: Catalyst Optimizer가 쿼리를 압축하고, 최적화시킨다.
  
  **cache vs persist**
  - cache: 메모리에 저장
  - persist: 메모리가 부족한 경우 디스크에 저장

  - cache(), persist()를 하자마자 액션이 없어도 캐싱이 된다.
  - 캐싱된 것들을 확인하고 지울 수 있다.
  ```python
  from pyspark.sql import SparkSession

  spark = SparkSession.builder.getOrCreate()
  sc = spark.sparkContext

  # 캐시된 모든 DataFrame 조회
  cached_dfs = spark.catalog.listTables()
  cached_dfs = [table for table in cached_dfs if spark.catalog.isCached(table.name)]

  for table in cached_dfs:
      print(f"캐시된 DataFrame: {table.name}")
      print(f"캐시된 DataFrame: {table}")

  # 캐시된 RDD 조회
  cache_size = sc._jsc.sc().getRDDStorageInfo()

  for rdd_info in cache_size:
      print(f"RDD ID: {rdd_info.id()}, Memory Size: {rdd_info.memSize()}, Disk Size: {rdd_info.diskSize()}")
  ```
  - 캐시된 것을 지우는 방법
  ```python
  spark.catalog.clearCache()
  ```

  - sql dataframe으로 캐싱하면 (to_spark().cache()) pandas on spark dataframe도 캐싱된다.

  - 왜 job이 한 action (심지어 count)에서 여러 개 생기는지 모르겠다. 이전 stage를 캐싱한다고 생각하면, 그냥 바로 여러 stage로 나누면 되지 않나?
  
---

### Keep:계속 유지
  - 지속적인 프로토타이핑으로 문제를 구체화시키자
  - "누구의" 문제인지를 알기 위하여 관련 정보를 계속해서 찾아보자
  - 질문을 두려워하지 말고, 모르는 것이 있다면 질문하자

---

### Problem: 문제가 발생한 행동
  - X

---
### Try: 다음 번에 새롭게 시도했으면 좋을 행동
  - "누구"를 설정하고, 다시 프로토타이핑하고, "누구"를 구체화하고 등 iteration을 계속 가져가자