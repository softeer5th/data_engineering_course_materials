## 리뷰
  ### 데일리 스크럼

  **선우님:**
  - Sotheby를 스크래핑하였는데, p 태그 중심으로 하여서 순서에 문제가 생기는 경우가 많았다.
  - regex를 잘 사용하여 패턴 매칭으로 데이터 추출을 추천하였다.
  - API 한번 호출로도 충분히 데이터를 잘 가져올 수 있는 것처럼 보였다.
  - 환율을 적용하고자 한다.

  **채연:**
  - Phillps를 스크래핑하였는데, 첫 API 호출로 모든 데이터를 가져오지는 못할 것처럼 보였다.
  - 상세 페이지는 SSR이기에 API 호출만으로 데이터를 가져오기 어려운 듯 하였다.
  - 따라서 bs4 사용을 혼합해야 할 것이다.
  - 환율 변환을 적용하고자 한다.

  **은태:**
  - Christie를 스크래핑하였는데, 한번 API 호출로 모든 데이터를 가져올 수 있었다.
  - 환율 변환을 이미 적용해보아서, 범위로 한 번에 데이터를 가져오고 transform 과정 중 merge하는 방식으로 데이터를 합쳐 환율을 변환하는 것이 더욱 빠를 것이라고 생각했다.
  - Title을 더욱 잘 파싱하고자 한다.
  - 작품 id를 만들기 위해 artist, title, height_cm, width_cm, year를 사용하고자 한다.
  
  
  ### 삽질 내역
  - ubuntu 20.04일 때, 기본 python은 3.8. 그 이상 버전을 사용하고 싶다면, deadsnakes ppa를 apt repo에 추가해야 한다.
  - 하둡 새 버전 다운로드가 너무 오래걸릴 수 있다. 일단 원래 컴퓨터에서 다운로드 받아보고, 속도 체크 후 base 이미지를 사용하는 것이 더 좋을 수 있다.

  ### Spark
  - spark는 application layer에서 동작하는 것이기에 storage layer인 hdfs와 연결하여 사용할 수 있다.
  - spark는 driver와 executor로 구성되어 있다. driver는 spark context를 생성하고, executor는 실제 작업을 수행한다.
  - spark job 파일은 jar, python 파일도 가능하다.
  - 그냥 모드를 local로 하거나, 마스터 주소를 지정하면 마스터에서 스케줄링을 수행한다.

---

### Keep:계속 유지
  - Spark를 사용할 때, driver와 executor의 로그도 보면서 디버깅을 해보자. 그러니까 한 마디로 꼼꼼하게 잘 읽자.

---

### Problem: 문제가 발생한 행동
  - X

---
### Try: 다음 번에 새롭게 시도했으면 좋을 행동
  - X