{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W3M2a - Hadoop Multi-Node Cluster on Docker\n",
    "\n",
    "---\n",
    "\n",
    "#### **학습 목표**\n",
    "- **W3M2의 첫 번째 파트**: Apache Hadoop에 대한 이해를 증명하기 위해 Docker를 사용하여 다중 노드 Hadoop 클러스터를 설정합니다. \n",
    "- 이 프로젝트를 통해 Hadoop 클러스터 구성과 Docker 컨테이너화를 실습할 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "#### **사전 지식**\n",
    "- **기능 요구사항**\n",
    "  1. **Docker 이미지**:\n",
    "     - **Docker 이미지는 완전히 작동 가능한 Hadoop 마스터 및 워커 노드를 포함해야 합니다.**\n",
    "     - Docker 컨테이너 실행 시 모든 필요한 Hadoop 서비스를 자동으로 시작해야 합니다.\n",
    "     - 마스터 노드와 워커 노드 간의 통신을 위해 동일한 Docker 네트워크에서 컨테이너가 연결될 수 있어야 합니다.\n",
    "\n",
    "  2. **HDFS 작업**:\n",
    "     - 마스터 노드에서 HDFS와 상호작용할 수 있어야 합니다.\n",
    "     - HDFS에 디렉토리를 생성, 파일을 업로드 및 다운로드할 수 있어야 합니다.\n",
    "     - 호스트 머신에서 HDFS 웹 인터페이스에 접속하여 파일 시스템을 모니터링할 수 있어야 합니다.\n",
    "\n",
    "  3. **클러스터 작업**:\n",
    "     - Hadoop 클러스터가 워커 노드를 인식하고 이를 분산 저장 및 처리에 활용할 수 있어야 합니다.\n",
    "     - YARN ResourceManager가 워커 노드의 NodeManager에 작업을 분배해야 합니다.\n",
    "     - 분산 처리를 보여주는 샘플 MapReduce 작업을 성공적으로 실행할 수 있어야 합니다.\n",
    "\n",
    "  4. **데이터 영속성**:\n",
    "     - Docker 컨테이너 내부의 Hadoop 데이터 디렉토리는 컨테이너 재시작 시 데이터를 유지하도록 구성되어야 합니다.\n",
    "     - 컨테이너가 중지되거나 재시작되더라도 HDFS에 저장된 데이터는 손실되지 않아야 합니다.\n",
    "\n",
    "  5. **문서화**:\n",
    "     - Docker 이미지를 빌드하고 컨테이너를 실행하는 방법에 대한 명확한 설명서를 제공해야 합니다.\n",
    "     - 컨테이너 내부에서 Hadoop을 설정하고 서비스를 시작하는 단계를 포함해야 합니다.\n",
    "     - 디렉토리 생성, 파일 업로드, MapReduce 작업 실행, 파일 검색과 같은 기본 HDFS 작업을 수행하는 방법을 문서화해야 합니다.\n",
    "\n",
    "---\n",
    "\n",
    "#### **프로그래밍 요구사항**\n",
    "1. **Docker 설정**:\n",
    "   - 로컬 머신에 Docker가 설치되지 않은 경우 설치해야 합니다.\n",
    "   - 여러 노드를 위한 Hadoop 환경을 구성하기 위한 Dockerfile을 생성해야 합니다.\n",
    "   - Dockerfile에서 Docker 이미지를 빌드하여 Hadoop 마스터 노드와 최소 1개의 워커 노드를 설정해야 합니다.\n",
    "\n",
    "2. **Hadoop 설정**:\n",
    "   - 다중 노드 클러스터를 위한 `core-site.xml`, `hdfs-site.xml`, `mapred-site.xml`, `yarn-site.xml` 파일을 구성해야 합니다.\n",
    "   - 마스터 및 워커 노드를 위한 Hadoop 환경 변수를 설정해야 합니다.\n",
    "   - 마스터 노드에서 HDFS 네임노드를 포맷해야 합니다.\n",
    "\n",
    "3. **네트워크 설정**:\n",
    "   - Docker 컨테이너 간 통신을 보장하기 위해 Docker 네트워크를 구성해야 합니다.\n",
    "   - 마스터 노드가 워커 노드를 인식하고 통신할 수 있도록 Hadoop 클러스터를 구성해야 합니다.\n",
    "\n",
    "4. **Hadoop 서비스 시작**:\n",
    "   - 마스터 노드에서 Hadoop NameNode 서비스를, 각 워커 노드에서 Hadoop DataNode 서비스를 시작해야 합니다.\n",
    "   - 모든 노드에서 HDFS가 정상적으로 실행 중임을 확인해야 합니다.\n",
    "   - 각 노드에서 YARN ResourceManager 및 NodeManager 서비스를 시작해야 합니다.\n",
    "\n",
    "5. **데이터 작업**:\n",
    "   - HDFS에 디렉토리를 생성해야 합니다.\n",
    "   - 로컬 파일 시스템에서 HDFS로 샘플 파일을 업로드해야 합니다.\n",
    "   - HDFS에서 파일을 검색하여 성공적으로 업로드되었음을 확인해야 합니다.\n",
    "   - Hadoop 클러스터에서 MapReduce 작업을 실행하여 기능을 검증해야 합니다.\n",
    "\n",
    "---\n",
    "\n",
    "#### **예상 결과 및 동작 예시**\n",
    "1. **실행 중인 컨테이너**:\n",
    "   - Hadoop 마스터 노드와 최소 1개의 워커 노드를 포함한 Docker 컨테이너 실행.\n",
    "   - 모든 Hadoop 서비스(NameNode, DataNode, ResourceManager, NodeManager 등)가 컨테이너 내에서 실행 중이어야 합니다.\n",
    "\n",
    "2. **HDFS 작업**:\n",
    "   - 마스터 노드에서 HDFS에 디렉토리를 생성할 수 있어야 합니다.\n",
    "   - 로컬 파일 시스템에서 HDFS로 파일을 업로드할 수 있어야 합니다.\n",
    "   - 업로드된 파일을 HDFS에서 로컬 파일 시스템으로 검색할 수 있어야 합니다.\n",
    "\n",
    "3. **클러스터 작업**:\n",
    "   - Hadoop 클러스터에서 샘플 MapReduce 작업을 실행할 수 있어야 합니다.\n",
    "   - 작업이 마스터 및 워커 노드를 활용하여 처리됨을 확인해야 합니다.\n",
    "\n",
    "4. **접근성**:\n",
    "   - 호스트 머신에서 HDFS 및 YARN 웹 인터페이스에 접속하여 클러스터 상태를 확인하고 파일 시스템 및 작업 모니터링 작업을 수행할 수 있어야 합니다.\n",
    "\n",
    "5. **제출물**:\n",
    "   - Hadoop 클러스터 설정에 사용된 Dockerfile 및 기타 설정 파일 제출.\n",
    "   - Docker 이미지 빌드, 컨테이너 실행, HDFS 및 MapReduce 작업 수행 방법에 대한 단계별 README 파일 제공."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker 이미지를 빌드하고 컨테이너를 실행하며 HDFS 작업을 수행하는 단계별 설명이 포함된 README 파일을 작성하는데 도와주세요.\n",
    "\n",
    "1. Docker 이미지 빌드\n",
    "docker-compose build\n",
    "\n",
    "2. 클러스터 실행\n",
    "docker-compose up -d\n",
    "\n",
    "2. 컨테이너 실행\n",
    "docker run -it -p 9870:9870 -p 8088:8088 -v {path}/data:/usr/local/hadoop/data hadoop-single-node\n",
    "\n",
    "3. HDFS 작업 수행-1 (폴더 생성)\n",
    "hdfs dfs -mkdir /{폴더}\n",
    "\n",
    "4. HDFS 작업 수행-2 (로컬에서 샘플 파일 생성 후 hdfs에 업로드)\n",
    "echo \"hello world\" > test.txt\n",
    "hdfs dfs -put test.txt /test/test.txt\n",
    "\n",
    "5. HDFS 작업 수행-3 (업로드된 파일을 HDFS에서 검색 후 업로드 확인)\n",
    "hdfs dfs -cat /test/test.txt\n",
    "\n",
    "6. MapReduce 작업 실행:\n",
    "hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar pi 16 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker 이미지를 빌드하고 컨테이너를 실행하는 방법에 대한 명확한 설명서를 제공\n",
    "Docker 이미지 빌드, 컨테이너 실행, HDFS 및 MapReduce 작업 수행 방법에 대한 단계별 README 파일 제공해야함\n",
    "1. 컨테이너 내부에서 Hadoop을 설정하고 서비스를 시작하는 단계를 포함\n",
    "2. 디렉토리 생성, 파일 업로드, MapReduce 작업 실행, 파일 검색과 같은 기본 HDFS 작업을 수행하는 방법을 문서화\n",
    "\n",
    "- Docker 이미지는 완전히 작동 가능한 Hadoop 마스터 및 워커 노드를 포함\n",
    "- Docker 컨테이너 실행 시 모든 필요한 Hadoop 서비스를 자동으로 시작\n",
    "- 마스터 노드에서 HDFS 네임노드를 포맷\n",
    "- 마스터 노드와 워커 노드 간의 통신을 위해 동일한 Docker 네트워크에서 컨테이너가 연결\n",
    "- 마스터 노드에서 HDFS와 상호작용(HDFS에 디렉토리를 생성, 파일을 업로드 및 다운로드)\n",
    "- 호스트 머신에서 HDFS 웹 인터페이스에 접속하여 파일 시스템을 모니터링\n",
    "- YARN ResourceManager가 워커 노드의 NodeManager에 작업을 분배 (분산 처리를 보여주는 샘플 MapReduce 작업을 성공적으로 실행)\n",
    "- 컨테이너 재시작 시 데이터를 유지 (컨테이너가 중지되거나 재시작되더라도 HDFS에 저장된 데이터는 손실되지 않음)\n",
    "- 마스터 노드에서 Hadoop NameNode 서비스를, 각 워커 노드에서 Hadoop DataNode 서비스를 시작해야 합니다.\n",
    "- 모든 노드에서 HDFS가 정상적으로 실행 중임을 확인해야 합니다.\n",
    "- 각 노드에서 YARN ResourceManager 및 NodeManager 서비스를 시작해야 합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up and Running an Apache Hadoop Multi-Node Cluster Using Docker\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Download Hadoop Binary**\n",
    "   - Visit the [Apache Hadoop Release Page](https://hadoop.apache.org/releases.html) and download the 3.3.6 version binary file along with its checksum signature.\n",
    "   - Place the downloaded files in the same directory as this repository before proceeding.\n",
    "\n",
    "2. **Install Docker and Docker Compose**\n",
    "   - Ensure Docker and Docker Compose are installed on your system.\n",
    "   - Verify installation with:\n",
    "     ```bash\n",
    "     docker --version\n",
    "     docker-compose --version\n",
    "     ```\n",
    "\n",
    "## Steps to Build and Run the Cluster\n",
    "\n",
    "### 1. Build Docker Images and Start Containers\n",
    "\n",
    "- Use Docker Compose to build the images and start the containers.\n",
    "\n",
    "```bash\n",
    "docker-compose up --build -d\n",
    "```\n",
    "\n",
    "This command will:\n",
    "- Build the Docker image specified in the `Dockerfile`.\n",
    "- Start the Hadoop master and worker nodes as defined in the `docker-compose.yml` file.\n",
    "\n",
    "### 2. Format the Namenode\n",
    "\n",
    "- Access the Hadoop master container:\n",
    "\n",
    "```bash\n",
    "docker exec -it hadoop-master bash\n",
    "```\n",
    "\n",
    "- Format the Namenode:\n",
    "\n",
    "```bash\n",
    "hdfs namenode -format\n",
    "```\n",
    "\n",
    "### 3. Access Hadoop Web Interfaces\n",
    "\n",
    "- HDFS Namenode UI: [http://localhost:9870](http://localhost:9870)\n",
    "- YARN Resource Manager UI: [http://localhost:8088](http://localhost:8088)\n",
    "\n",
    "## Performing HDFS Operations\n",
    "\n",
    "### 1. Create a Folder in HDFS\n",
    "\n",
    "```bash\n",
    "hdfs dfs -mkdir /<folder_name>\n",
    "```\n",
    "\n",
    "### 2. Upload a File to HDFS\n",
    "\n",
    "- Create a sample file on your local machine:\n",
    "\n",
    "```bash\n",
    "echo \"hello world\" > test.txt\n",
    "```\n",
    "\n",
    "- Upload the file to the previously created folder in HDFS:\n",
    "\n",
    "```bash\n",
    "hdfs dfs -put test.txt /<folder_name>/test.txt\n",
    "```\n",
    "\n",
    "### 3. Verify the Uploaded File\n",
    "\n",
    "- View the contents of the uploaded file in HDFS:\n",
    "\n",
    "```bash\n",
    "hdfs dfs -cat /<folder_name>/test.txt\n",
    "```\n",
    "\n",
    "## Running a MapReduce Job\n",
    "\n",
    "Execute a sample MapReduce job to calculate the value of Pi:\n",
    "\n",
    "```bash\n",
    "hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar pi 16 1000\n",
    "```\n",
    "\n",
    "This command uses 16 mappers and performs 1,000 iterations to estimate the value of Pi.\n",
    "\n",
    "## File Descriptions\n",
    "\n",
    "- **Dockerfile**: Defines the custom Hadoop Docker image.\n",
    "- **docker-compose.yml**: Specifies the multi-node cluster configuration with one master and multiple workers.\n",
    "- **core-site.xml, hdfs-site.xml, mapred-site.xml, yarn-site.xml**: Hadoop configuration files to set up HDFS, MapReduce, and YARN.\n",
    "\n",
    "## Notes\n",
    "\n",
    "- Ensure all configuration files (e.g., `core-site.xml`, `hdfs-site.xml`) are correctly placed and customized for your setup before starting the cluster.\n",
    "- Use `docker logs <container_name>` to debug any issues.\n",
    "\n",
    "Feel free to modify and extend this setup as needed for your use case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
